<h1>
Learning with Artificial Intelligence using Neural Networks
<br />McKinney Boyd High School
<br />Christian Duffee
<br />Trevor Thai Kim Nguyen
<br />Sammy Shin
</h1>

Neural networks are artificial intelligence computer programs designed to mimic the natural behavior of the brain. Neural networks are made up of input, hidden and output nodes connected to each other by weighted connections. Input is propagated down from the input nodes, through the hidden nodes and to the output nodes by these weighted connections. The changing of these weights is all that is needed to completely transform the nature of the network. This makes it incredibly versatile; it is here that neural networks differ from traditional programs. Neural networks are "black boxes", the programmers do not directly control, or even know the weights of the neural network. Rather, the beauty of neural networks is that they learn the specific task by itself, independent of humans. This allow computers to perform tasks humans are generally poor at programming computers to do. For example, Google has pioneered the field of artificial intelligence by creating and training neural networks to recognize shapes in images and patterns in text. Additionally, just recently they made the first AI that was able to beat a world class Go player. Before this Go was the last board game that humans were able to outperform computers. There are several ways to train a neural network. This project aims to explore and explain these different methods and their various advantages and disadvantages. They are listed below.

<p>
<h3>Brute Force Algorithm</h3>
The most naive of algorithms, this works by checked each possible weight combination and chooses the best ones. The advantage to this is that it is guarantined to create a working network. The disadvantage is that it is extremely slow; the time of completion grows exponentially with the complexity of the network. Thus it is only suited for the simplest networks. An addition caveat is that the brute force algorithm can only test weight values of some multiple since they can be any of near infinite arbitrary decimal values. To make up for this the greedy algorithm is run after the brute force algorithm or order to optimize results between the multiple of the weights tested.
[LAUNCH BRUTE FORCE BUTTON]

<p>
<h3>Greedy Algorithm</h3>
This algorithm works by generating a random network and trying modification of weights to minimize error. The advantage to this is that it is very fast; the time it takes increases linearly with the complexity of the network. The disadvantage is that it can get stuck at local minimums of error; it can get struck at a good solution that is not necessarily the best.
[LAUNCH GREEDY ALGORITHM BUTTON]

<p>
<h3>Genetic Algorithm</h3>
This algorithm works by generating several random neural networks and making them compete in some way against each other. The one that preforms the best creates a number of children, each a clone of the parent except with mutations. These children then compete and the one best at completing the task then creates its own children with mutations. This continues until a child has a perfect neural network. The advantage of this is that it is moderately fast and will eventually
[LAUNCH GENETIC ALGORITHM BUTTON]

<p>
<h3>Backpropagation</h3>
Backpropagation is a relatively recent discovery in computer science. The idea is to consider a neural network as a many dimensional function. To change the weights, first the error between the expected and actual output is calculated. Then the derivation of each weight is calculated and multiplied by this error to find the amount each weight should be modifying. This is widely considered to be the best method to teach the neural network and is the method most modern researchers and companies use.
[LAUNCH BACKPROPAGATION ALGORITHM BUTTON]